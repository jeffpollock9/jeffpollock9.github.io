#+BEGIN_EXPORT html
---
layout: post
title: "The ordered logistic distribution"
permalink: /:title/
tags: [tensorflow, stan, soccer]
---
#+END_EXPORT

#+PROPERTY: header-args:jupyter-python :session *Python* :eval no-export

I was very pleased to wake up today to find that some code I wrote for the ordered
logistic distribution had been [[https://github.com/tensorflow/probability/pull/753][accepted into TensorFlow Probability]] (TFP)! My son also
went to bed early so I decided to celebrate with this blog post.

The ordered logistic distribution is one of those annoying ones which people tend to
call lots of different things and also write down differently too. The implementation I
used in TFP follows [[https://mc-stan.org/docs/2_22/functions-reference/ordered-logistic-distribution.html][Stan]] and [[https://docs.pymc.io/api/distributions/discrete.html#pymc3.distributions.discrete.OrderedLogistic][PyMC3]] and hopefully the documentation for it will appear on
the TensorFlow website with the next TFP release. Until then it can be seen in the
Python docstrings.

The distribution is useful for modelling categorical outcomes which contain some sort of
ordering for example modelling the outcome of a survey question where the responses are
"bad", "ok", and "good". 

I've decided to show an example of all this with some soccer data, in fact the same data
I used [[https://jeffpollock9.github.io/checking-soccer-models-with-PPC/][in a previous post]] when I diagnosed a problem with the model underestimating the
draw probability. I wonder if it will be the case again?

I'm going to consider the (ordered) outcomes of matches as the goal difference from the
home team perspective clipped at $\pm3$ and because I can't help myself, I'm going to
code it up in Stan and TFP and see how they compare. I'm not going to write down any
maths for this model either - I think the code for it should suffice.

* Data

#+BEGIN_SRC jupyter-python :exports both :results output
  import pandas as pd
  import numpy as np

  data_list = []
  for x in range(10, 19):
      season = f"{x}{x+1}"
      url = f"http://www.football-data.co.uk/mmz4281/{season}/E0.csv"
      data_list.append(pd.read_csv(url))

  soccer_data = (
      pd.concat(data_list, axis=0)
      .rename(
          columns={
              "HomeTeam": "home_team_name",
              "AwayTeam": "away_team_name",
              "FTHG": "home_goals",
              "FTAG": "away_goals",
          }
      )
      .filter(regex="^home_|^away")
      .dropna()
      .astype({"home_goals": np.int32, "away_goals": np.int32})
      .assign(
          clipped_score_difference=lambda x: np.clip(
              x["home_goals"] - x["away_goals"], -3, 3
          )
      )
  )

  team_names = np.unique(
      pd.concat([soccer_data["home_team_name"], soccer_data["away_team_name"]])
  )


  def team_code(team_name):
      def fn(df):
          codes = pd.Categorical(df[team_name], categories=team_names).codes
          return codes.astype(np.int32)

      return fn


  soccer_data = soccer_data.assign(
      home_team=team_code("home_team_name"), away_team=team_code("away_team_name"),
  )

  print(soccer_data.sample(6, random_state=123))
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE
    home_team_name away_team_name  home_goals  away_goals  \
3        Newcastle        Arsenal           0           0   
33         Norwich       West Ham           0           0   
188        Watford        Chelsea           1           2   
321      West Brom      Liverpool           0           1   
66         Chelsea        Arsenal           2           0   
127    Bournemouth        Arsenal           1           2   

     clipped_score_difference  home_team  away_team  
3                           0         21          0  
33                          0         22         32  
188                        -1         30         10  
321                        -1         31         17  
66                          2         10          0  
127                        -1          6          0  
#+END_EXAMPLE

* Stan

Note that there is a bug in the latest version of stan with the ordered logistic
distribution so we cannot use the vectorised version easily, see [[https://discourse.mc-stan.org/t/ordered-logistic-lpmf/9799][the stan forums]].

#+NAME: ordered-stan-file
#+BEGIN_SRC stan :file ordered.stan
  data {
      int<lower = 1> n;
      int<lower = 2> num_teams;
      int<lower = 1, upper = num_teams> home_team[n];
      int<lower = 1, upper = num_teams> away_team[n];
      int<lower = 1, upper = 7> clipped_score_difference_p4[n];
  }

  parameters {
      ordered[6] cutpoints;
      vector[num_teams] team_strength;
      real<lower = 0.0> team_scale;
  }

  model {
      vector[n] location = team_strength[home_team] - team_strength[away_team];
      team_strength ~ normal(0.0, team_scale);
      team_scale ~ exponential(1.0);
      for (i in 1:n) {
          clipped_score_difference_p4[i] ~ ordered_logistic(location[i], cutpoints);
      }
  }
#+END_SRC

#+RESULTS: ordered-stan-file
[[file:ordered.stan]]

#+BEGIN_SRC jupyter-python :exports code :results output :var stan_file=ordered-stan-file
  import pystan
  import arviz as az
  import time as tm

  go_faster_flags = ["-O3", "-march=native", "-ffast-math"]
  summary_vars = ["mean", "sd", "hpd_3%", "hpd_97%", "ess_bulk", "r_hat"]

  stan_model = pystan.StanModel(stan_file, extra_compile_args=go_faster_flags)

  stan_data = {
      "n": len(soccer_data),
      "num_teams": len(team_names),
      "home_team": soccer_data["home_team"] + 1,
      "away_team": soccer_data["away_team"] + 1,
      "clipped_score_difference_p4": soccer_data["clipped_score_difference"] + 4,
  }

  start_stan = tm.time()
  stan_fit = az.from_pystan(
      stan_model.sampling(data=stan_data, chains=12),
      coords={"team_names": team_names},
      dims={"team_strength": ["team_names"]},
  )
  end_stan = tm.time()

  print(f"stan took {end_stan - start_stan:.2f} seconds")
#+END_SRC

#+RESULTS:
: stan took 130.70 seconds

#+BEGIN_SRC jupyter-python :results output :exports both :file misc/stan_energy.png
  az.plot_energy(stan_fit)
#+END_SRC

#+RESULTS:
[[file:misc/stan_energy.png]]

#+BEGIN_SRC jupyter-python :exports both :results output
  print(az.summary(stan_fit).filter(items=summary_vars))
#+END_SRC

#+RESULTS:
#+BEGIN_EXAMPLE
                    mean     sd  hpd_3%  hpd_97%  ess_bulk  r_hat
cutpoints[0]      -3.134  0.078  -3.276   -2.984   11216.0   1.00
cutpoints[1]      -2.137  0.054  -2.241   -2.038   15671.0   1.00
cutpoints[2]      -1.008  0.040  -1.086   -0.935   16482.0   1.00
cutpoints[3]       0.206  0.037   0.140    0.276   14863.0   1.00
cutpoints[4]       1.294  0.043   1.214    1.375   15999.0   1.00
cutpoints[5]       2.429  0.060   2.317    2.544   17647.0   1.00
team_strength[0]   1.050  0.143   0.766    1.307    2388.0   1.00
team_strength[1]  -0.401  0.153  -0.690   -0.109    2808.0   1.00
team_strength[2]  -0.213  0.266  -0.708    0.293    7820.0   1.00
team_strength[3]  -0.341  0.218  -0.764    0.052    5398.0   1.00
team_strength[4]  -0.352  0.283  -0.872    0.178    8299.0   1.00
team_strength[5]  -0.330  0.219  -0.740    0.079    5850.0   1.00
team_strength[6]  -0.197  0.175  -0.529    0.130    3575.0   1.00
team_strength[7]  -0.291  0.213  -0.679    0.112    5643.0   1.00
team_strength[8]  -0.167  0.171  -0.497    0.145    3407.0   1.00
team_strength[9]  -0.754  0.221  -1.170   -0.345    5879.0   1.00
team_strength[10]  1.083  0.141   0.819    1.354    2320.0   1.00
team_strength[11] -0.012  0.153  -0.295    0.276    2727.0   1.00
team_strength[12]  0.444  0.139   0.189    0.717    2283.0   1.01
team_strength[13] -0.343  0.163  -0.647   -0.043    3133.0   1.00
team_strength[14] -0.841  0.217  -1.262   -0.452    5322.0   1.00
team_strength[15] -0.438  0.190  -0.786   -0.073    4344.0   1.00
team_strength[16]  0.319  0.164   0.012    0.633    2996.0   1.00
team_strength[17]  1.012  0.144   0.752    1.294    2479.0   1.00
team_strength[18]  1.534  0.143   1.259    1.799    2330.0   1.00
team_strength[19]  1.081  0.141   0.805    1.339    2353.0   1.00
team_strength[20] -0.374  0.265  -0.877    0.109    8578.0   1.00
team_strength[21] -0.085  0.145  -0.359    0.190    2406.0   1.00
team_strength[22] -0.332  0.174  -0.663   -0.008    3540.0   1.00
team_strength[23] -0.460  0.185  -0.812   -0.115    4080.0   1.00
team_strength[24] -0.525  0.264  -1.005   -0.016    8349.0   1.00
team_strength[25]  0.181  0.151  -0.114    0.454    2554.0   1.00
team_strength[26] -0.058  0.144  -0.316    0.223    2456.0   1.00
team_strength[27] -0.222  0.150  -0.496    0.068    2521.0   1.00
team_strength[28] -0.015  0.148  -0.286    0.271    2600.0   1.00
team_strength[29]  0.902  0.139   0.650    1.170    2372.0   1.00
team_strength[30] -0.123  0.172  -0.443    0.202    3340.0   1.00
team_strength[31] -0.113  0.144  -0.381    0.161    2364.0   1.00
team_strength[32] -0.006  0.145  -0.284    0.261    2367.0   1.00
team_strength[33] -0.341  0.188  -0.702    0.004    4094.0   1.00
team_strength[34] -0.325  0.190  -0.679    0.039    4339.0   1.00
team_scale         0.613  0.081   0.466    0.763   14344.0   1.00
#+END_EXAMPLE

#+BEGIN_SRC jupyter-python :results output :exports both :file misc/stan_team_strength.png
  az.plot_forest(stan_fit, var_names="team_strength", combined=True)
#+END_SRC

#+RESULTS:
[[file:misc/stan_team_strength.png]]

* TFP

#+BEGIN_SRC jupyter-python :results output :exports both
  import tensorflow as tf
  import tensorflow_probability as tfp

  tfd = tfp.distributions
  tfb = tfp.bijectors

  Root = tfd.JointDistributionCoroutine.Root


  def make_cutpoints(x):
      bijector = tfb.Ordered()
      return bijector.inverse(x)


  def model():
      unconstrained_cutpoints = yield Root(
          tfd.MultivariateNormalDiag(loc=tf.zeros(6), scale_diag=tf.ones(6))
      )
      team_scale = yield Root(tfd.Exponential(1.0))
      team_strength = yield tfd.MultivariateNormalDiag(
          tf.zeros(num_teams), scale_diag=tf.fill([num_teams], team_scale)
      )

      cutpoints = make_cutpoints(unconstrained_cutpoints)
      location = tf.gather(team_strength, home_team) - tf.gather(team_strength, away_team)

      clipped_score_difference_p3 = yield tfd.OrderedLogistic(
          cutpoints=cutpoints, location=location,
      )
#+END_SRC

#+RESULTS:
